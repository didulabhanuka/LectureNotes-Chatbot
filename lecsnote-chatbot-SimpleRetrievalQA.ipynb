{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d43f3e61",
   "metadata": {},
   "source": [
    "Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00d1f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain-huggingface chromadb transformers torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75feed0",
   "metadata": {},
   "source": [
    "2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151d9ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "import os, getpass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca207c20",
   "metadata": {},
   "source": [
    "3. Authenticate Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db5f969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for your Hugging Face API key if not already set\n",
    "if not os.getenv(\"HUGGINGFACEHUB_API_TOKEN\"):\n",
    "    os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass.getpass(\"Enter your Hugging Face API key: \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc8cc0c",
   "metadata": {},
   "source": [
    "4. Load and Split CTSE Lecture Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1348490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your lecture notes PDF file\n",
    "loader = PyPDFLoader(\"CTSE_Lecture_Notes.pdf\")  # Replace with your file name\n",
    "documents = loader.load()\n",
    "\n",
    "# Split into chunks (important for context-aware retrieval)\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "docs = splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e739d0e",
   "metadata": {},
   "source": [
    "5. Create Embeddings & Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70866c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = \"./chroma_langchain_db\"\n",
    "\n",
    "# Use Sentence Transformer to convert text into vectors\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "if os.path.exists(persist_directory):\n",
    "    # If already exists, load the existing DB\n",
    "    vector_store = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n",
    "\n",
    "else:\n",
    "    # Otherwise, create and save\n",
    "    vector_store = Chroma.from_documents(\n",
    "        documents=docs,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=persist_directory\n",
    "    )\n",
    "    vector_store.persist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c9b1e6",
   "metadata": {},
   "source": [
    "6. Set Up Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b64d3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a retriever that returns top 4 relevant chunks\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1749706",
   "metadata": {},
   "source": [
    "7. Initialize Flan-T5 Base LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c66ee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Hugging Face's flan-t5-base model for QA generation\n",
    "model_id = \"google/flan-t5-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
    "\n",
    "# Create a text2text generation pipeline\n",
    "flan_pipeline = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer)\n",
    "llm = HuggingFacePipeline(pipeline=flan_pipeline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78130138",
   "metadata": {},
   "source": [
    "8. Build Retrieval QA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128db24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create LangChain QA chain with the retriever and LLM\n",
    "qa_chain = RetrievalQA.from_llm(llm=llm, retriever=retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f740e2df",
   "metadata": {},
   "source": [
    "9. Define Chatbot Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b5880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple chatbot function to ask questions\n",
    "def chatbot(query: str) -> str:\n",
    "    return qa_chain.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8262e9f",
   "metadata": {},
   "source": [
    "10. Batch Querying â€“ Test Multiple Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c626907f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try sample questions from your lecture notes\n",
    "questions = [\n",
    "    \"What is software engineering?\",\n",
    "    \"Explain the Agile methodology.\",\n",
    "    \"What are current trends in AI and ML?\",\n",
    "    \"Define DevOps in software development.\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    print(f\"\\nðŸŸ¡ Question: {q}\")\n",
    "    print(f\"ðŸŸ¢ Answer: {chatbot(q)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
