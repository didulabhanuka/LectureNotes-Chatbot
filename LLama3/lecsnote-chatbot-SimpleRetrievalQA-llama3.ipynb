{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d43f3e61",
   "metadata": {},
   "source": [
    "Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00d1f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain-huggingface langchain-community fastembed chromadb transformers torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75feed0",
   "metadata": {},
   "source": [
    "2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151d9ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import FastEmbedEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "import os, getpass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca207c20",
   "metadata": {},
   "source": [
    "3. Authenticate Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db5f969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for your Hugging Face API key if not already set\n",
    "if not os.getenv(\"HUGGINGFACEHUB_API_TOKEN\"):\n",
    "    os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass.getpass(\"Enter your Hugging Face API key: \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc8cc0c",
   "metadata": {},
   "source": [
    "4. Load and Split CTSE Lecture Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1348490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your lecture notes PDF file\n",
    "loader = PyPDFLoader(\"../CTSE_Lecture_Notes.pdf\")  # Replace with your file name\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "# Split into chunks (important for context-aware retrieval)\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2048,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    add_start_index=True,\n",
    ")\n",
    "docs = splitter.split_documents(pages)\n",
    "print(f\"Split {len(pages)} pages into {len(docs)} chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e739d0e",
   "metadata": {},
   "source": [
    "5. Create Embeddings & Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70866c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = \"./chroma_langchain_db\"\n",
    "\n",
    "# Use FastEmbed to convert text into vectors\n",
    "embeddings = FastEmbedEmbeddings()\n",
    "\n",
    "if os.path.exists(persist_directory):\n",
    "    # If already exists, load the existing DB\n",
    "    vector_store = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n",
    "    print(\"Loaded existing vector store.\")\n",
    "\n",
    "else:\n",
    "    # Otherwise, create and save\n",
    "    vector_store = Chroma.from_documents(\n",
    "        documents=docs,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=persist_directory\n",
    "    )\n",
    "    vector_store.persist()\n",
    "    print(\"Created and saved new vector store.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c9b1e6",
   "metadata": {},
   "source": [
    "6. Set Up Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b64d3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriever with threshold filtering\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\n",
    "        \"k\": 3,\n",
    "        \"score_threshold\": 0.5,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1749706",
   "metadata": {},
   "source": [
    "7. Initialize LLaMA 3 via Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c66ee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLaMA 3 via Ollama\n",
    "llm = ChatOllama(model=\"tinyllama\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78130138",
   "metadata": {},
   "source": [
    "8. Build Retrieval QA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b5e531",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_llm(llm=llm, retriever=retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f740e2df",
   "metadata": {},
   "source": [
    "9. Define Chatbot Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b5880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(query: str):\n",
    "    # Retrieve relevant documents (using updated LangChain method)\n",
    "    retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "    if not retrieved_docs:\n",
    "        print(\"\\n[Info] No relevant documents were retrieved using the score threshold. No answer will be provided.\\n\")\n",
    "        return\n",
    "\n",
    "    # Proceed with the QA chain if relevant documents exist\n",
    "    result = qa_chain.invoke({\"question\": query})\n",
    "    print(\"\\nAnswer:\", result[\"answer\"])\n",
    "\n",
    "    # Optionally print sources\n",
    "    if \"source_documents\" in result:\n",
    "        for doc in result[\"source_documents\"]:\n",
    "            print(\"Source:\", doc.metadata.get(\"source\", \"Unknown\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8262e9f",
   "metadata": {},
   "source": [
    "10. Batch Querying â€“ Test Multiple Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d0a2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask(\"What is capcut?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feef3110",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
